{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48203e5a-79ec-4b45-ba51-aeb3f4b71fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import sklearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f977ff99-216b-4057-8805-2d1630e23a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"melb_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "09ef9853-1e7d-4be1-ae54-e4803c535d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set the target\n",
    "y = data['Price']\n",
    "\n",
    "# Firstly drop categorical data types\n",
    "melb_features = data.drop(['Price'], axis=1) #drop the target column\n",
    "\n",
    "X = melb_features.select_dtypes(exclude=['object'])\n",
    "\n",
    "# Divide data into training and validation sets\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0e5342df-432e-43be-bb2f-1b7934083d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEAL WITH MISSING VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bbc12c-a9bc-447a-a18e-b346e1eeace1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the rows with empty cells from the original dataframe\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "#Drop the columns with empty cells\n",
    "#firstly, get the names of columns with empty cells\n",
    "cols_with_empty_cells = [col for col in X_train.columns if X_train[col].isnull().any()]\n",
    "\n",
    "#secondly, drop the columns with the empty cells\n",
    "removed_X_train_cols = X_train.drop(cols_with_empty_cells, axis=1)\n",
    "removed_X_valid_cols = X_valid.drop(cols_with_empty_cells, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "285bf039-a8e5-4932-acbe-1a9afc7b5598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPUTE VALUES IN EMPTY CELLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856eafb5-5098-4f70-92cc-4173d609ad37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Impute values\n",
    "imputer = SimpleImputer()\n",
    "imputed_X_train_values = pd.DataFrame(imputer.fit_transform(X_train))\n",
    "imputed_X_valid_values = pd.DataFrame(imputer.transform(X_valid))\n",
    "\n",
    "# Imputation removed column names so we put them back\n",
    "imputed_X_train_values.columns = X_train.columns\n",
    "imputed_X_valid_values.columns = X_valid.columns\n",
    "\n",
    "# See the new columns and their values\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a1294cab-e29c-4c2c-adfe-f35fe0a2c02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPUTE VALUES IN EMPTY CELLS AND INDICATE IN A COLUMN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a36ecd-6091-4f11-be89-a3da3ed7d1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make new columns indicating what will be imputed\n",
    "# The column will have booleans as values\n",
    "for col in cols_with_empty_cells:\n",
    "    X_train[col + '_was_missing'] = X_train[col].isnull()\n",
    "    X_valid[col + '_was_missing'] = X_valid[col].isnull()\n",
    "\n",
    "# Impute values\n",
    "imputer = SimpleImputer()\n",
    "imputed_X_train_values = pd.DataFrame(imputer.fit_transform(X_train))\n",
    "imputed_X_valid_values = pd.DataFrame(imputer.transform(X_valid))\n",
    "\n",
    "# Imputation removed column names so we put them back\n",
    "imputed_X_train_values.columns = X_train.columns\n",
    "imputed_X_valid_values.columns = X_valid.columns\n",
    "\n",
    "# See the new columns and their values\n",
    "X_train.head() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fe55ac7a-dc1a-46e9-89aa-bab944c52d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DROP DUPLICATE VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d80a661-3064-411e-9cff-19976c2a5cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for the number of duplicate rows in the dataset\n",
    "X_train.duplicated().sum()\n",
    "\n",
    "# Drop the duplicate rows\n",
    "X_train.drop_duplicates(inplace=True)\n",
    "X_valid.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d752ba-7372-46c6-87ba-c7db79fadc8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
